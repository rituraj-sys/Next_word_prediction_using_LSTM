{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "KulNrtegWIsY"
      },
      "outputs": [],
      "source": [
        "file = '''My Name Is\" is a song by American rapper Eminem from his second album The Slim Shady LP (1999).\n",
        "It is also the opening song and lead single of the album. The song samples British singer Labi Siffre's 1975 track \"I Got The...\" as a bass and guitar riff played by British pop rock duo Chas & Dave.\n",
        "The song was ranked at #26 on \"VH1's 100 Greatest Songs of the '90s\".\n",
        "\"My Name Is\" was also ranked #6 on Q Magazine's \"1001 Best Songs Ever\".[3] \"My Name Is\" peaked at number 36 on the Billboard Hot 100, becoming Eminem's first top 40 hit there. Outside the United States\n",
        "\"My Name Is\" peaked within the top ten of the charts in Iceland, New Zealand, Norway, Ireland, and United Kingdom.\n",
        "The song was placed at number 39 by Rolling Stone on their list of \"100 Greatest Hip-Hop songs of all time\" in April 2016.\n",
        "The recording garnered Eminem his first Grammy Award for Best Rap Solo Performance at the 42nd Grammy Awards in 2000.\n",
        "Background On the first day of recording, Eminem and Dr. Dre finished \"My Name Is\" in an hour. The song contains a sample of Labi Siffre's track \"I Got The...\". Siffre, who is openly gay, said in a 2012 interview that he refused to clear the sample until sexist and homophobic lyrics were removed from the song: \"Dissing the victims of bigotry – women as bitches, homosexuals as faggots – is lazy writing. Diss the bigots not their victims.\n",
        "The original uncensored version of the song with the aforementioned offending lyrics is mistakenly included on the compilation The Source Hip Hop Music Awards 1999. The bass and guitar riff used in the sample was performed by Siffre's session musicians Chas Hodges and Dave Peacock, who later became the duo Chas & Dave.\n",
        "\"My Name Is\" is written in the key of F major.[8] Famous names referenced in the song include Nine Inch Nails,\n",
        "the Spice Girls, and Pamela Anderson (Pamela Lee).\n",
        "Music video The video premiered on MTV Total Request Live on January 21, 1999. It was directed by Phillip Atwell, who would later direct music videos for several other Eminem songs, including \"The Real Slim Shady\", \"Stan\", \"Lose Yourself\", and \"Just Lose It\".\n",
        "The video starts out with a stereotypical redneck family watching television, who then come across a show starring \"Marshall Mathers\" (Eminem's real name). As the video goes on, Eminem parodies several TV shows and movies. He also imitates then-President of the United States Bill Clinton, Johnny Carson, a porn star, and others. Basketball player Gheorghe Mureșan has a cameo appearance as a ventriloquist with Eminem being used as the dummy in the scene. Dr. Dre, the song's producer, also has a cameo as a doctor.\n",
        "It also features a Monica Lewinski lookalike, and Eminem imitating a chemistry teacher. Eminem is seen wearing a red tuxedo in some parts of the video, something that he would pay homage to in his 2020 single “Gnat”, 21 years after “My Name Is” was originally released.\n",
        "The video was ranked #71 in NME's 100 Greatest Music Videos.[10] As of 2019, the music video has been replaced on all official sites (including the official Eminem YouTube account and MTV's holding accounts) with alternative lyrics online making it more advertiser friendly.\n",
        "Lines such as, \"Well, since age 12, I felt like I'm someone else 'Cause I hung my original self from the top bunk with a belt,\" are replaced with \"Since age 12 I felt like a caged elf Who stayed to himself in one space, chasing his tail,\" also with lines referencing ripping Pamela Lee's breasts off replaced with ripping her lips off and kissing them, saying how they feel soft like silicon.'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "9b0RDAo7XDkm"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = Tokenizer()\n",
        "token.fit_on_texts([file])"
      ],
      "metadata": {
        "id": "bW8LsH9VXYx7"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hozOjjAxYb-o",
        "outputId": "7c5095fc-9ea7-4846-9fb6-5ecf8bd6efae"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "332"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = []\n",
        "for sentence in file.split('\\n'):\n",
        "  sequence = token.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(sequence)):\n",
        "    input_sequence.append(sequence[:i+1])"
      ],
      "metadata": {
        "id": "iQlgTi2sZqEO"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max([len(i) for i in input_sequence])"
      ],
      "metadata": {
        "id": "tJG_Xah7k8Ja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bafe3cf5-87bd-48dd-e47d-dc2e0bd99e74"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "pad = pad_sequences(input_sequence,maxlen=86,padding='pre')"
      ],
      "metadata": {
        "id": "unJ-vkr5kOCl"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkV1C9X8vQ9n",
        "outputId": "f2f8780b-57d6-4c1a-d195-03a3ba1f4a9c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  13,  11],\n",
              "       [  0,   0,   0, ...,  13,  11,   4],\n",
              "       [  0,   0,   0, ...,  11,   4,   4],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 329, 330, 331],\n",
              "       [  0,   0,   0, ..., 330, 331,  43],\n",
              "       [  0,   0,   0, ..., 331,  43, 332]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = pad[:,:-1]\n",
        "y = pad[:,-1]\n",
        "y,x"
      ],
      "metadata": {
        "id": "zcEtdmlTvVt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb36fb62-b355-46c8-f399-f957f3ae6a51"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 11,   4,   4,   2,   8,  17,  94,  95,   9,  26,  22,  96,  44,\n",
              "          1,  45,  46,  97,  27,   4,  16,   1,  98,   8,   3,  99,  47,\n",
              "          5,   1,  44,   1,   8, 100,  48, 101,  49,  28, 102,  50,  19,\n",
              "         51,   1,  10,   2,  52,   3,  53,  54, 103,  17,  48, 104, 105,\n",
              "         55,  29,  30,   8,  14,  31,  23, 106,   7, 107,  24,  32,  25,\n",
              "          5,   1, 108,  11,   4,  14,  16,  31, 109,   7, 110, 111, 112,\n",
              "         56,  25, 113, 114,  13,  11,   4,  57,  23,  58, 115,   7,   1,\n",
              "        116, 117,  24, 118,  59,  33,  34, 119, 120, 121, 122,   1,  35,\n",
              "         60,  11,   4,  57, 123,   1,  34, 124,   5,   1, 125,   6, 126,\n",
              "        127, 128, 129, 130,   3,  35, 131,   8,  14, 132,  23,  58, 133,\n",
              "         17, 134, 135,   7,  61, 136,   5,  24,  32,  62,  63,  25,   5,\n",
              "         64, 137,   6, 138, 139,  65, 140,   9,  22,  33,  66, 141,  67,\n",
              "         56, 142, 143, 144,  23,   1, 145,  66,  68,   6, 146,   7,   1,\n",
              "         33, 148,   5,  65,   9,   3,  69,  70, 149,  13,  11,   4,   6,\n",
              "        150, 151,   1,   8, 152,   2,  36,   5,  49,  28,  50,  19,  51,\n",
              "          1, 153,  20,   4, 154, 155, 156,   6,   2, 157, 158,  71,  37,\n",
              "        159,  38, 160,   1,  36, 161, 162,   3, 163,  39, 164, 165,  26,\n",
              "          1,   8, 166,   1,  72,   5, 167,  73, 168,  10, 169, 170,  10,\n",
              "        171,  73,   4, 172, 173, 174,   1, 175, 176,  61,  72,  74, 177,\n",
              "        178,   5,   1,   8,  12,   1, 179, 180,  39,   4, 181, 182,   7,\n",
              "          1, 183,   1, 184,  62,  63,  21,  68,  27,   1,  52,   3,  53,\n",
              "         54,  75,   6,   1,  36,  14, 185,  17,  28, 186, 187,  29, 188,\n",
              "          3,  30, 189,  20,  76, 190,   1,  55,  29,  30,  11,   4,   4,\n",
              "        191,   6,   1, 192,   5, 193, 194, 195, 196, 197, 198,   6,   1,\n",
              "          8, 199, 200, 201, 202, 203, 204,   3,  40, 205,  40, 206,  15,\n",
              "          1,  15, 207,   7, 208, 209, 210, 211,   7, 212,  77,  27,  18,\n",
              "         14, 213,  17, 214, 215,  20,  78,  76, 216,  21,  79,  67,  80,\n",
              "        217,   9,  25,  81,   1,  82,  45,  46, 218,  83, 219,   3, 220,\n",
              "         83,  18,  15, 221, 222,  12,   2, 223, 224, 225, 226, 227,  20,\n",
              "         84, 228, 229,   2, 230, 231, 232, 233,  59,  82,  11,  10,   1,\n",
              "         15, 234,   7,   9, 235,  80, 236, 237,   3, 238,  37,  16, 239,\n",
              "         84, 240,   5,   1,  35,  60, 241, 242, 243, 244,   2, 245, 246,\n",
              "          3, 247, 248, 249, 250, 251,  41,   2,  85, 252,  10,   2, 253,\n",
              "         12,   9, 254,  75,  10,   1, 255,   6,   1, 256,  69,  70,   1,\n",
              "        257, 258,  16,  41,   2,  85,  10,   2, 259,  16, 260,   2, 261,\n",
              "        262, 263,   3,   9, 264,   2, 265, 266,   9,   4, 267, 268,   2,\n",
              "        269, 270,   6, 271, 272,   5,   1,  15, 273,  71,  37,  78, 274,\n",
              "        275,  38,   6,  22, 276,  47, 277,  77, 278, 279, 280,  11, 281,\n",
              "         14, 282, 283,  15,  14,  31, 284,   6, 285,  24,  32,  21,  79,\n",
              "        286,  10,   5, 287,   1,  21,  15,  41, 288,  42,   7,  64,  86,\n",
              "        289,  81,   1,  86,   9, 290, 291,   3, 292, 293, 294,  12, 295,\n",
              "         39, 296, 297,  18, 298, 299, 300, 301,  10, 302,  88,  89,  90,\n",
              "         19,  91,  43, 303, 304, 305, 306,  19, 307,  13,  74, 308,  26,\n",
              "          1,  34, 309,  12,   2, 310, 311,  42,  12,  88,  89,  90,  19,\n",
              "         91,  43,   2, 312, 313,  20, 314,  38, 315,   6, 316, 317, 318,\n",
              "         22, 319,  16,  12,  87, 320,  92,  40, 321, 322,  93,  42,  12,\n",
              "         92, 323, 324,  93,   3, 325, 326, 327, 328, 329, 330, 331,  43,\n",
              "        332], dtype=int32),\n",
              " array([[  0,   0,   0, ...,   0,   0,  13],\n",
              "        [  0,   0,   0, ...,   0,  13,  11],\n",
              "        [  0,   0,   0, ...,  13,  11,   4],\n",
              "        ...,\n",
              "        [  0,   0,   0, ..., 328, 329, 330],\n",
              "        [  0,   0,   0, ..., 329, 330, 331],\n",
              "        [  0,   0,   0, ..., 330, 331,  43]], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "aPVCAdApw9jT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0084dee-e9cc-4f92-87f7-6e79fa5f0003"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(612, 85)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpbJ9_gVsG3e",
        "outputId": "b1c2e338-3d86-4695-d551-c61a1a47ee43"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(612,)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes = 338)"
      ],
      "metadata": {
        "id": "atNqXU4wssyL"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6bDJ4qLtb1H",
        "outputId": "a0aa6d10-bd79-45a3-cb8d-36a6f15de790"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(612, 338)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BG9sBVttgiq",
        "outputId": "0c6cc3f9-1dfc-4936-edd3-58b9fc5b5128"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from keras.layers import LSTM, Embedding, Dense"
      ],
      "metadata": {
        "id": "2shlnV6etr9Y"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =  Sequential()\n",
        "model.add(Embedding(333,100,input_length=85))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(338,activation = 'softmax'))"
      ],
      "metadata": {
        "id": "gJL4K2fBbeR2"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam', metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "WJVXjSKqcTXC"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcYL0NcacpKH",
        "outputId": "509a1384-c6cd-4c3b-df6f-13dbdbcec35a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 85, 100)           33300     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 150)               150600    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 338)               51038     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 234938 (917.73 KB)\n",
            "Trainable params: 234938 (917.73 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UisXoHEjec8S",
        "outputId": "3da6045d-8fca-4faa-9203-f642c3be4d6f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 6s 145ms/step - loss: 5.7784 - accuracy: 0.0474\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 4s 222ms/step - loss: 5.5603 - accuracy: 0.0621\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 5.4223 - accuracy: 0.0621\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 5.3886 - accuracy: 0.0621\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 5.3663 - accuracy: 0.0621\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 5s 232ms/step - loss: 5.3332 - accuracy: 0.0621\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 5.2851 - accuracy: 0.0621\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 5.2293 - accuracy: 0.0637\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 3s 146ms/step - loss: 5.1242 - accuracy: 0.0735\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 4s 227ms/step - loss: 4.9824 - accuracy: 0.0801\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 4.8116 - accuracy: 0.1029\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 3s 141ms/step - loss: 4.6352 - accuracy: 0.0997\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 3s 141ms/step - loss: 4.4437 - accuracy: 0.1291\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 4s 222ms/step - loss: 4.2428 - accuracy: 0.1373\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 4.0180 - accuracy: 0.1683\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 3s 142ms/step - loss: 3.7775 - accuracy: 0.1634\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 3s 142ms/step - loss: 3.5792 - accuracy: 0.2010\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 4s 223ms/step - loss: 3.3906 - accuracy: 0.2304\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 3s 147ms/step - loss: 3.1924 - accuracy: 0.2500\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 3s 142ms/step - loss: 2.9735 - accuracy: 0.2958\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 2.7763 - accuracy: 0.3611\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 4s 223ms/step - loss: 2.6219 - accuracy: 0.3791\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 2.4618 - accuracy: 0.4150\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 2.3056 - accuracy: 0.4722\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 2.1836 - accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 4s 220ms/step - loss: 2.0430 - accuracy: 0.5523\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 3s 142ms/step - loss: 1.9231 - accuracy: 0.5915\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 3s 141ms/step - loss: 1.8066 - accuracy: 0.6340\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 1.7096 - accuracy: 0.6422\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 4s 227ms/step - loss: 1.6115 - accuracy: 0.6977\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 1.5228 - accuracy: 0.7288\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 1.4305 - accuracy: 0.7565\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 3s 140ms/step - loss: 1.3590 - accuracy: 0.7778\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 4s 218ms/step - loss: 1.2885 - accuracy: 0.8056\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 1.2214 - accuracy: 0.8382\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 1.1565 - accuracy: 0.8693\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 3s 140ms/step - loss: 1.0888 - accuracy: 0.8775\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 4s 227ms/step - loss: 1.0317 - accuracy: 0.8742\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.9870 - accuracy: 0.8971\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.9292 - accuracy: 0.9216\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 3s 146ms/step - loss: 0.8817 - accuracy: 0.9297\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 4s 224ms/step - loss: 0.8504 - accuracy: 0.9379\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.8039 - accuracy: 0.9412\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.7568 - accuracy: 0.9428\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.7223 - accuracy: 0.9542\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 4s 222ms/step - loss: 0.6811 - accuracy: 0.9690\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.6473 - accuracy: 0.9673\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 3s 142ms/step - loss: 0.6184 - accuracy: 0.9657\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 3s 142ms/step - loss: 0.5970 - accuracy: 0.9608\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 4s 221ms/step - loss: 0.5620 - accuracy: 0.9690\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.5444 - accuracy: 0.9624\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 3s 142ms/step - loss: 0.5277 - accuracy: 0.9641\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.4907 - accuracy: 0.9641\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 4s 218ms/step - loss: 0.4677 - accuracy: 0.9739\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.4503 - accuracy: 0.9722\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.4289 - accuracy: 0.9739\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.4091 - accuracy: 0.9739\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 4s 220ms/step - loss: 0.3898 - accuracy: 0.9771\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.3768 - accuracy: 0.9755\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.3623 - accuracy: 0.9771\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 3s 141ms/step - loss: 0.3541 - accuracy: 0.9755\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 4s 223ms/step - loss: 0.3417 - accuracy: 0.9755\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.3266 - accuracy: 0.9788\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.3182 - accuracy: 0.9755\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 3s 142ms/step - loss: 0.3089 - accuracy: 0.9771\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 4s 220ms/step - loss: 0.2885 - accuracy: 0.9788\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.2807 - accuracy: 0.9820\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.2662 - accuracy: 0.9804\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.2608 - accuracy: 0.9804\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 4s 220ms/step - loss: 0.2498 - accuracy: 0.9788\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.2415 - accuracy: 0.9788\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 3s 146ms/step - loss: 0.2353 - accuracy: 0.9788\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.2259 - accuracy: 0.9788\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 4s 223ms/step - loss: 0.2213 - accuracy: 0.9771\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.2110 - accuracy: 0.9804\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.2046 - accuracy: 0.9820\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.1992 - accuracy: 0.9788\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 4s 227ms/step - loss: 0.1947 - accuracy: 0.9804\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.1883 - accuracy: 0.9804\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 3s 147ms/step - loss: 0.1847 - accuracy: 0.9755\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 3s 146ms/step - loss: 0.1811 - accuracy: 0.9755\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 4s 226ms/step - loss: 0.1746 - accuracy: 0.9771\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.1682 - accuracy: 0.9820\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 3s 146ms/step - loss: 0.1676 - accuracy: 0.9771\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.1595 - accuracy: 0.9788\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 4s 222ms/step - loss: 0.1560 - accuracy: 0.9755\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 3s 146ms/step - loss: 0.1652 - accuracy: 0.9788\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 3s 147ms/step - loss: 0.1547 - accuracy: 0.9804\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.1477 - accuracy: 0.9771\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 4s 225ms/step - loss: 0.1432 - accuracy: 0.9788\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.1414 - accuracy: 0.9788\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.1380 - accuracy: 0.9771\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 3s 146ms/step - loss: 0.1343 - accuracy: 0.9788\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 4s 221ms/step - loss: 0.1312 - accuracy: 0.9755\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 3s 150ms/step - loss: 0.1281 - accuracy: 0.9755\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.1240 - accuracy: 0.9804\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 3s 149ms/step - loss: 0.1208 - accuracy: 0.9820\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 4s 210ms/step - loss: 0.1192 - accuracy: 0.9788\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 3s 142ms/step - loss: 0.1181 - accuracy: 0.9788\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.1138 - accuracy: 0.9804\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7adea816b0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#for i in range(5):\n",
        "#prediction>>\n",
        "text = input('Enter the text:')\n",
        "token_text = token.texts_to_sequences([text])[0]\n",
        "pad_text = pad_sequences([token_text],maxlen = 85,padding = 'pre')\n",
        "\n",
        "position = np.argmax(model.predict(pad_text))\n",
        "for word,index in token.word_index.items():\n",
        "  if index == position:\n",
        "    #text = text + ' ' + word\n",
        "    print(word)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSLXIq8yg2Zx",
        "outputId": "1674bba5-c895-42bb-f0a9-6fadce472366"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text:my name is is written in the\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "key\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA8fAXWbiyPn",
        "outputId": "72ab3c95-19b9-4832-affe-88de405993fa"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30G87bM7jtAx",
        "outputId": "3b34d99c-8de8-468a-8392-8589658b9d98"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'a': 2,\n",
              " 'and': 3,\n",
              " 'is': 4,\n",
              " 'of': 5,\n",
              " 'in': 6,\n",
              " 'on': 7,\n",
              " 'song': 8,\n",
              " 'eminem': 9,\n",
              " 'as': 10,\n",
              " 'name': 11,\n",
              " 'with': 12,\n",
              " 'my': 13,\n",
              " 'was': 14,\n",
              " 'video': 15,\n",
              " 'also': 16,\n",
              " 'by': 17,\n",
              " 'it': 18,\n",
              " 'i': 19,\n",
              " 'who': 20,\n",
              " 'music': 21,\n",
              " 'his': 22,\n",
              " 'at': 23,\n",
              " '100': 24,\n",
              " 'songs': 25,\n",
              " 'from': 26,\n",
              " '1999': 27,\n",
              " \"siffre's\": 28,\n",
              " 'chas': 29,\n",
              " 'dave': 30,\n",
              " 'ranked': 31,\n",
              " 'greatest': 32,\n",
              " 'first': 33,\n",
              " 'top': 34,\n",
              " 'united': 35,\n",
              " 'sample': 36,\n",
              " 'he': 37,\n",
              " 'to': 38,\n",
              " 'lyrics': 39,\n",
              " 'pamela': 40,\n",
              " 'has': 41,\n",
              " 'replaced': 42,\n",
              " 'like': 43,\n",
              " 'album': 44,\n",
              " 'slim': 45,\n",
              " 'shady': 46,\n",
              " 'single': 47,\n",
              " 'british': 48,\n",
              " 'labi': 49,\n",
              " 'track': 50,\n",
              " 'got': 51,\n",
              " 'bass': 52,\n",
              " 'guitar': 53,\n",
              " 'riff': 54,\n",
              " 'duo': 55,\n",
              " 'best': 56,\n",
              " 'peaked': 57,\n",
              " 'number': 58,\n",
              " \"eminem's\": 59,\n",
              " 'states': 60,\n",
              " 'their': 61,\n",
              " 'hip': 62,\n",
              " 'hop': 63,\n",
              " 'all': 64,\n",
              " 'recording': 65,\n",
              " 'grammy': 66,\n",
              " 'for': 67,\n",
              " 'awards': 68,\n",
              " 'dr': 69,\n",
              " 'dre': 70,\n",
              " 'that': 71,\n",
              " 'victims': 72,\n",
              " '–': 73,\n",
              " 'original': 74,\n",
              " 'used': 75,\n",
              " 'later': 76,\n",
              " '21': 77,\n",
              " 'would': 78,\n",
              " 'videos': 79,\n",
              " 'several': 80,\n",
              " 'including': 81,\n",
              " 'real': 82,\n",
              " 'lose': 83,\n",
              " 'then': 84,\n",
              " 'cameo': 85,\n",
              " 'official': 86,\n",
              " 'lines': 87,\n",
              " 'since': 88,\n",
              " 'age': 89,\n",
              " '12': 90,\n",
              " 'felt': 91,\n",
              " 'ripping': 92,\n",
              " 'off': 93,\n",
              " 'american': 94,\n",
              " 'rapper': 95,\n",
              " 'second': 96,\n",
              " 'lp': 97,\n",
              " 'opening': 98,\n",
              " 'lead': 99,\n",
              " 'samples': 100,\n",
              " 'singer': 101,\n",
              " '1975': 102,\n",
              " 'played': 103,\n",
              " 'pop': 104,\n",
              " 'rock': 105,\n",
              " '26': 106,\n",
              " \"vh1's\": 107,\n",
              " \"'90s\": 108,\n",
              " '6': 109,\n",
              " 'q': 110,\n",
              " \"magazine's\": 111,\n",
              " '1001': 112,\n",
              " 'ever': 113,\n",
              " '3': 114,\n",
              " '36': 115,\n",
              " 'billboard': 116,\n",
              " 'hot': 117,\n",
              " 'becoming': 118,\n",
              " '40': 119,\n",
              " 'hit': 120,\n",
              " 'there': 121,\n",
              " 'outside': 122,\n",
              " 'within': 123,\n",
              " 'ten': 124,\n",
              " 'charts': 125,\n",
              " 'iceland': 126,\n",
              " 'new': 127,\n",
              " 'zealand': 128,\n",
              " 'norway': 129,\n",
              " 'ireland': 130,\n",
              " 'kingdom': 131,\n",
              " 'placed': 132,\n",
              " '39': 133,\n",
              " 'rolling': 134,\n",
              " 'stone': 135,\n",
              " 'list': 136,\n",
              " 'time': 137,\n",
              " 'april': 138,\n",
              " '2016': 139,\n",
              " 'garnered': 140,\n",
              " 'award': 141,\n",
              " 'rap': 142,\n",
              " 'solo': 143,\n",
              " 'performance': 144,\n",
              " '42nd': 145,\n",
              " '2000': 146,\n",
              " 'background': 147,\n",
              " 'day': 148,\n",
              " 'finished': 149,\n",
              " 'an': 150,\n",
              " 'hour': 151,\n",
              " 'contains': 152,\n",
              " 'siffre': 153,\n",
              " 'openly': 154,\n",
              " 'gay': 155,\n",
              " 'said': 156,\n",
              " '2012': 157,\n",
              " 'interview': 158,\n",
              " 'refused': 159,\n",
              " 'clear': 160,\n",
              " 'until': 161,\n",
              " 'sexist': 162,\n",
              " 'homophobic': 163,\n",
              " 'were': 164,\n",
              " 'removed': 165,\n",
              " 'dissing': 166,\n",
              " 'bigotry': 167,\n",
              " 'women': 168,\n",
              " 'bitches': 169,\n",
              " 'homosexuals': 170,\n",
              " 'faggots': 171,\n",
              " 'lazy': 172,\n",
              " 'writing': 173,\n",
              " 'diss': 174,\n",
              " 'bigots': 175,\n",
              " 'not': 176,\n",
              " 'uncensored': 177,\n",
              " 'version': 178,\n",
              " 'aforementioned': 179,\n",
              " 'offending': 180,\n",
              " 'mistakenly': 181,\n",
              " 'included': 182,\n",
              " 'compilation': 183,\n",
              " 'source': 184,\n",
              " 'performed': 185,\n",
              " 'session': 186,\n",
              " 'musicians': 187,\n",
              " 'hodges': 188,\n",
              " 'peacock': 189,\n",
              " 'became': 190,\n",
              " 'written': 191,\n",
              " 'key': 192,\n",
              " 'f': 193,\n",
              " 'major': 194,\n",
              " '8': 195,\n",
              " 'famous': 196,\n",
              " 'names': 197,\n",
              " 'referenced': 198,\n",
              " 'include': 199,\n",
              " 'nine': 200,\n",
              " 'inch': 201,\n",
              " 'nails': 202,\n",
              " 'spice': 203,\n",
              " 'girls': 204,\n",
              " 'anderson': 205,\n",
              " 'lee': 206,\n",
              " 'premiered': 207,\n",
              " 'mtv': 208,\n",
              " 'total': 209,\n",
              " 'request': 210,\n",
              " 'live': 211,\n",
              " 'january': 212,\n",
              " 'directed': 213,\n",
              " 'phillip': 214,\n",
              " 'atwell': 215,\n",
              " 'direct': 216,\n",
              " 'other': 217,\n",
              " 'stan': 218,\n",
              " 'yourself': 219,\n",
              " 'just': 220,\n",
              " 'starts': 221,\n",
              " 'out': 222,\n",
              " 'stereotypical': 223,\n",
              " 'redneck': 224,\n",
              " 'family': 225,\n",
              " 'watching': 226,\n",
              " 'television': 227,\n",
              " 'come': 228,\n",
              " 'across': 229,\n",
              " 'show': 230,\n",
              " 'starring': 231,\n",
              " 'marshall': 232,\n",
              " 'mathers': 233,\n",
              " 'goes': 234,\n",
              " 'parodies': 235,\n",
              " 'tv': 236,\n",
              " 'shows': 237,\n",
              " 'movies': 238,\n",
              " 'imitates': 239,\n",
              " 'president': 240,\n",
              " 'bill': 241,\n",
              " 'clinton': 242,\n",
              " 'johnny': 243,\n",
              " 'carson': 244,\n",
              " 'porn': 245,\n",
              " 'star': 246,\n",
              " 'others': 247,\n",
              " 'basketball': 248,\n",
              " 'player': 249,\n",
              " 'gheorghe': 250,\n",
              " 'mureșan': 251,\n",
              " 'appearance': 252,\n",
              " 'ventriloquist': 253,\n",
              " 'being': 254,\n",
              " 'dummy': 255,\n",
              " 'scene': 256,\n",
              " \"song's\": 257,\n",
              " 'producer': 258,\n",
              " 'doctor': 259,\n",
              " 'features': 260,\n",
              " 'monica': 261,\n",
              " 'lewinski': 262,\n",
              " 'lookalike': 263,\n",
              " 'imitating': 264,\n",
              " 'chemistry': 265,\n",
              " 'teacher': 266,\n",
              " 'seen': 267,\n",
              " 'wearing': 268,\n",
              " 'red': 269,\n",
              " 'tuxedo': 270,\n",
              " 'some': 271,\n",
              " 'parts': 272,\n",
              " 'something': 273,\n",
              " 'pay': 274,\n",
              " 'homage': 275,\n",
              " '2020': 276,\n",
              " '“gnat”': 277,\n",
              " 'years': 278,\n",
              " 'after': 279,\n",
              " '“my': 280,\n",
              " 'is”': 281,\n",
              " 'originally': 282,\n",
              " 'released': 283,\n",
              " '71': 284,\n",
              " \"nme's\": 285,\n",
              " '10': 286,\n",
              " '2019': 287,\n",
              " 'been': 288,\n",
              " 'sites': 289,\n",
              " 'youtube': 290,\n",
              " 'account': 291,\n",
              " \"mtv's\": 292,\n",
              " 'holding': 293,\n",
              " 'accounts': 294,\n",
              " 'alternative': 295,\n",
              " 'online': 296,\n",
              " 'making': 297,\n",
              " 'more': 298,\n",
              " 'advertiser': 299,\n",
              " 'friendly': 300,\n",
              " 'such': 301,\n",
              " 'well': 302,\n",
              " \"i'm\": 303,\n",
              " 'someone': 304,\n",
              " 'else': 305,\n",
              " \"'cause\": 306,\n",
              " 'hung': 307,\n",
              " 'self': 308,\n",
              " 'bunk': 309,\n",
              " 'belt': 310,\n",
              " 'are': 311,\n",
              " 'caged': 312,\n",
              " 'elf': 313,\n",
              " 'stayed': 314,\n",
              " 'himself': 315,\n",
              " 'one': 316,\n",
              " 'space': 317,\n",
              " 'chasing': 318,\n",
              " 'tail': 319,\n",
              " 'referencing': 320,\n",
              " \"lee's\": 321,\n",
              " 'breasts': 322,\n",
              " 'her': 323,\n",
              " 'lips': 324,\n",
              " 'kissing': 325,\n",
              " 'them': 326,\n",
              " 'saying': 327,\n",
              " 'how': 328,\n",
              " 'they': 329,\n",
              " 'feel': 330,\n",
              " 'soft': 331,\n",
              " 'silicon': 332}"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    }
  ]
}